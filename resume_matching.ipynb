{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c3fb78e-9861-4c88-b50d-3a800704bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Librarys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71151a78-aa97-408b-96ea-6b8c5a9c6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resume, Job Description\n",
    "resume_text = \"I am a PHP Laravel developer.\"\n",
    "job_text = \"Looking for a Laravel expert with PHP knowledge.\"\n",
    "resume_text = resume_text.lower()\n",
    "job_text = job_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6135630-41fb-40bd-8083-8a365f483b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: List\n",
    "documents = [resume_text, job_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "557f4cc7-a1d9-49af-b49c-cfbd30d0f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: TF-IDF Model\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25ca7762-6f09-4e06-80f5-491adf865962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Calculate Similarity (0 to 1 scale)\n",
    "similarity_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36042f05-c256-4121-9dff-5c40c953b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert out of 10\n",
    "score_out_of_10 = math.ceil(round(similarity_score * 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aaf76f5f-c981-4570-8132-ba0fd207e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score (out of 10): 4\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Result\n",
    "print(\"Matching Score (out of 10):\", score_out_of_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fd646da-5a7f-437c-9834-72a664972ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume ID 1 vs Job ID 101 → Matching Score (out of 10): 4\n",
      "Resume ID 2 vs Job ID 102 → Matching Score (out of 10): 4\n",
      "Resume ID 3 vs Job ID 103 → Matching Score (out of 10): 6\n",
      "Resume ID 4 vs Job ID 104 → Matching Score (out of 10): 7\n",
      "Resume ID 5 vs Job ID 105 → Matching Score (out of 10): 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "# Step 1: CSV file load\n",
    "df = pd.read_csv(\"resume_job_dataset.csv\")\n",
    "\n",
    "# Step 2: calculate matching resume & job\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    resume = row['resume_text']\n",
    "    job = row['job_description']\n",
    "    \n",
    "    documents = [resume.lower(), job.lower()]\n",
    "    tfidf = vectorizer.fit_transform(documents)\n",
    "    score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "    \n",
    "    print(f\"Resume ID {row['resume_id']} vs Job ID {row['job_id']} → Matching Score (out of 10): {math.ceil(round(score * 10, 2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f110a5-7fec-4ab6-b890-07e795127b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume ID 1 vs Job ID 101 → Matching Score (out of 10): 10\n",
      "Resume ID 2 vs Job ID 102 → Matching Score (out of 10): 9\n",
      "Resume ID 3 vs Job ID 103 → Matching Score (out of 10): 9\n",
      "Resume ID 4 vs Job ID 104 → Matching Score (out of 10): 10\n",
      "Resume ID 5 vs Job ID 105 → Matching Score (out of 10): 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "# spaCy model load\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# CSV load\n",
    "# df = pd.read_csv(\"professional_resume_job_dataset.csv\")\n",
    "df = pd.read_csv(\"resume_job_dataset.csv\")\n",
    "\n",
    "# score store\n",
    "scores = []\n",
    "\n",
    "# find similarity for per resume-job\n",
    "for index, row in df.iterrows():\n",
    "    resume_doc = nlp(str(row['resume_text']))\n",
    "    job_doc = nlp(str(row['job_description']))\n",
    "    similarity = resume_doc.similarity(job_doc)\n",
    "    score_out_of_10 = (round(similarity * 10, 2))\n",
    "    scores.append(math.ceil(score_out_of_10))\n",
    "    print(f\"Resume ID {row['resume_id']} vs Job ID {row['job_id']} → Matching Score (out of 10): {math.ceil(score_out_of_10)}\")\n",
    "\n",
    "# add new column\n",
    "df['semantic_score_out_of_10'] = scores\n",
    "\n",
    "# store on new csv\n",
    "# df.to_csv(\"resume_job_semantic_scores.csv\", index=False)\n",
    "\n",
    "# print(\"✅ Done! Matching scores saved in 'resume_job_semantic_scores.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a54a95b-8519-4dde-a464-98c62ff6b6a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect model/corpus name",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapi\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load pretrained FastText model\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# model = api.load(\"fasttext-wiki-news-subwords-300\")  # Optional: use 'wiki.simple' if available\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwiki.simple\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Optional: use 'wiki.simple' if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\downloader.py:492\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, return_path)\u001b[39m\n\u001b[32m    490\u001b[39m file_name = _get_filename(name)\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIncorrect model/corpus name\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    493\u001b[39m folder_dir = os.path.join(BASE_DIR, name)\n\u001b[32m    494\u001b[39m path = os.path.join(folder_dir, file_name)\n",
      "\u001b[31mValueError\u001b[39m: Incorrect model/corpus name"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load pretrained FastText model\n",
    "# model = api.load(\"fasttext-wiki-news-subwords-300\")  # Optional: use 'wiki.simple' if available\n",
    "model = api.load(\"wiki.simple\")  # Optional: use 'wiki.simple' if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17293af-54ad-44a9-ab54-a818f41a33ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHAN GADGET\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a03c4f1-8f73-4ccc-b1fa-151f3e948c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume ID 1 vs Job ID 101 → Matching Score (out of 10): 8\n",
      "Resume ID 2 vs Job ID 102 → Matching Score (out of 10): 9\n",
      "Resume ID 3 vs Job ID 103 → Matching Score (out of 10): 10\n",
      "Resume ID 4 vs Job ID 104 → Matching Score (out of 10): 9\n",
      "Resume ID 5 vs Job ID 105 → Matching Score (out of 10): 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "\n",
    "# Load FastText model (may take time initially)\n",
    "model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"resume_job_dataset.csv\")\n",
    "\n",
    "def get_sentence_vector(sentence, model):\n",
    "    words = sentence.lower().split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return None\n",
    "    return sum(word_vectors) / len(word_vectors)\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "# Calculate similarity scores\n",
    "scores = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    resume_vec = get_sentence_vector(row['resume_text'], model)\n",
    "    job_vec = get_sentence_vector(row['job_description'], model)\n",
    "    \n",
    "    if resume_vec is not None and job_vec is not None:\n",
    "        similarity = cosine_similarity(resume_vec, job_vec)\n",
    "        score_10 = round(similarity * 10, 2)\n",
    "    else:\n",
    "        score_10 = 0.0\n",
    "    \n",
    "    scores.append(score_10)\n",
    "    print(f\"Resume ID {row['resume_id']} vs Job ID {row['job_id']} → Matching Score (out of 10): {math.ceil(score_10)}\")\n",
    "\n",
    "# Add scores to DataFrame\n",
    "df['fasttext_score_out_of_10'] = scores\n",
    "\n",
    "# Save updated CSV\n",
    "# df.to_csv(\"resume_job_fasttext_scores.csv\", index=False)\n",
    "\n",
    "# print(\"✅ Done! FastText scores saved to 'resume_job_fasttext_scores.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91a9a5-13fb-45a9-8c3c-aebf7bb55d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Gensim)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
